{
 "metadata": {
  "name": "",
  "signature": "sha256:3126450fee46d425d053d56dd7624489fc0c6f144973101631e7c080f2cfecea"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The Grid Search Module\n",
      "\n",
      "The :mod:`diogenes.grid_search` module provides tools for finding the best classifier, testing classifier sensitivity to data sets, and cross-validating classifier performance. \n",
      "\n",
      "Most of the work you will do in the `grid_search` module centers around the class: :class:`diogenes.grid_search.experiment.Experiment`. \n",
      "\n",
      "An `Experiment` exhaustively fits a number of different classifiers to different data and measures performance. The Experiment searches across a number of dimensions:\n",
      "\n",
      "1. *Classifiers* and hyper-parameters\n",
      "2. Different *subsets* of data to classify\n",
      "3. Different ways to cross-validate a subset of the data (*partition iterators*)\n",
      "\n",
      "Subsets are distinct from partition iterators in that subsets select the portion of the data that will be used for both training and testing, while partition iterators take the data given by the subset and splits it into training and testing sets.\n",
      "\n",
      "We will begin by exploring classifiers, and we will explore subsets and partition iterators later."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Experiments, Classifiers and Hyperparameters\n",
      "\n",
      "We start by preparing the wine data set for binary classification"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import diogenes\n",
      "import numpy as np\n",
      "data = diogenes.read.open_csv_url(\n",
      "    'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv',\n",
      "    delimiter=';')\n",
      "labels = data['quality']\n",
      "labels = labels < np.average(labels)\n",
      "M = diogenes.modify.remove_cols(data, 'quality')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We then design an experiment that fits data against Random Forest and SVC with a number of hyperparameters:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.svm import SVC\n",
      "clfs = [{'clf': RandomForestClassifier, 'n_estimators': [10,50],\n",
      "         'max_features': ['sqrt','log2'], 'random_state': [0]},\n",
      "        {'clf': SVC, 'C': [0.1, 1.0, 10], 'kernel': ['linear', 'rbf'], \n",
      "         'max_iter': [1000], 'random_state': [0]}]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This experiment will fit the data to one classifier for each element in the Cartesian product of the parameters that we passed in. It's equivalent to creating all the following classifiers:\n",
      "\n",
      "    RandomForestClassifier(n_estimators=10, max_features='sqrt', random_state=0)\n",
      "    RandomForestClassifier(n_estimators=10, max_features='log2', random_state=0)\n",
      "    RandomForestClassifier(n_estimators=50, max_features='sqrt', random_state=0)\n",
      "    RandomForestClassifier(n_estimators=50, max_features='log2', random_state=0)\n",
      "    SVC(C=0.1, kernel=linear, max_iter=1000, random_state=0)\n",
      "    SVC(C=0.1, kernel=rbf, max_iter=1000, random_state=0)\n",
      "    SVC(C=1.0, kernel=linear, max_iter=1000, random_state=0)\n",
      "    SVC(C=1.0, kernel=rbf, max_iter=1000, random_state=0)\n",
      "    SVC(C=10, kernel=linear, max_iter=1000, random_state=0)\n",
      "    SVC(C=10, kernel=rbf, max_iter=1000, random_state=0)\n",
      "    \n",
      "See :class:`diogenes.grid_search.experiment.Experiment` for details on how arguments to `Experiment` work.\n",
      "\n",
      "We can then create and run our experiment, and look at scores to see which classifier and which hyperparameters performed the best."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp = diogenes.grid_search.experiment.Experiment(M, labels, clfs=clfs)\n",
      "exp.run()\n",
      "sorted_trial_with_score = sorted(exp.average_score().iteritems(), key=lambda x: x[1], reverse=True)\n",
      "\n",
      "for trial, score in sorted_trial_with_score[:3]:\n",
      "    print trial\n",
      "    print score\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Trial(clf=<class 'sklearn.ensemble.forest.RandomForestClassifier'>, clf_params={'n_estimators': 50, 'max_features': 'sqrt', 'random_state': 0}, subset=<class 'diogenes.grid_search.subset.SubsetNoSubset'>, subset_params={}, cv=<class 'sklearn.cross_validation.KFold'>, cv_params={})\n",
        "0.740104773283\n",
        "\n",
        "Trial(clf=<class 'sklearn.ensemble.forest.RandomForestClassifier'>, clf_params={'n_estimators': 50, 'max_features': 'log2', 'random_state': 0}, subset=<class 'diogenes.grid_search.subset.SubsetNoSubset'>, subset_params={}, cv=<class 'sklearn.cross_validation.KFold'>, cv_params={})\n",
        "0.740104773283\n",
        "\n",
        "Trial(clf=<class 'sklearn.ensemble.forest.RandomForestClassifier'>, clf_params={'n_estimators': 10, 'max_features': 'sqrt', 'random_state': 0}, subset=<class 'diogenes.grid_search.subset.SubsetNoSubset'>, subset_params={}, cv=<class 'sklearn.cross_validation.KFold'>, cv_params={})\n",
        "0.730916098323\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/sklearn/svm/base.py:204: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "/Library/Python/2.7/site-packages/sklearn/svm/base.py:204: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "/Library/Python/2.7/site-packages/sklearn/svm/base.py:204: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
        "  % self.max_iter, ConvergenceWarning)\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It looks like our best-performing classifier is `RandomForest` with `n_estimators=50` with a score of about `0.74`. We also notice that the `max_features` hyperparameter does not affect score in this case.\n",
      "\n",
      "If you want to use a standard set of classifiers rather than specifying your own, you can look use :mod:`diogenes.grid_search.standard_clfs`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exp = diogenes.grid_search.experiment.Experiment(M, labels, clfs=diogenes.grid_search.standard_clfs.std_clfs)\n",
      "exp.run()\n",
      "sorted_trial_with_score = sorted(exp.average_score().iteritems(), key=lambda x: x[1], reverse=True)\n",
      "\n",
      "for trial, score in sorted_trial_with_score[:3]:\n",
      "    print trial\n",
      "    print score\n",
      "    print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Trial(clf=<class 'sklearn.ensemble.forest.RandomForestClassifier'>, clf_params={'n_estimators': 30, 'max_features': 'log2', 'n_jobs': 1, 'max_depth': 7}, subset=<class 'diogenes.grid_search.subset.SubsetNoSubset'>, subset_params={}, cv=<class 'sklearn.cross_validation.KFold'>, cv_params={})\n",
        "0.757665504965\n",
        "\n",
        "Trial(clf=<class 'sklearn.ensemble.forest.RandomForestClassifier'>, clf_params={'n_estimators': 10, 'max_features': 'log2', 'n_jobs': 1, 'max_depth': 7}, subset=<class 'diogenes.grid_search.subset.SubsetNoSubset'>, subset_params={}, cv=<class 'sklearn.cross_validation.KFold'>, cv_params={})\n",
        "0.756645764041\n",
        "\n",
        "Trial(clf=<class 'sklearn.ensemble.forest.RandomForestClassifier'>, clf_params={'n_estimators': 30, 'max_features': 'sqrt', 'n_jobs': 1, 'max_depth': 7}, subset=<class 'diogenes.grid_search.subset.SubsetNoSubset'>, subset_params={}, cv=<class 'sklearn.cross_validation.KFold'>, cv_params={})\n",
        "0.756236016554\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Library/Python/2.7/site-packages/sklearn/svm/base.py:204: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
        "  % self.max_iter, ConvergenceWarning)\n",
        "/Library/Python/2.7/site-packages/sklearn/svm/base.py:204: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
        "  % self.max_iter, ConvergenceWarning)\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Subset Iterators and Partition Iterators\n",
      "\n",
      "In addition to iterating over different classifiers and hyper-parameters, we can also iterate over different subsets of data and different methods of cross validation. We'll discuss subsetters first.\n",
      "\n",
      "### Subset Iterators\n",
      "\n",
      "A Subset Iterators iterates over different subsets of the data. `Experiment` will attempt to fit all the classifiers to, and do cross-validation on, each subset. A number of these subset iterators are defined in :mod:`diogenes.grid_search.subset`, including:\n",
      "\n",
      "* :class:`diogenes.grid_search.subset.SubsetSweepNumRows`, which takes subsets with different numbers of rows, ignoring which     row has which label\n",
      "* :class:`diogenes.grid_search.subset.SubsetRandomRowsActualDistribution`, which takes a subset of data that have the same \n",
      "  frequency distribution of labels as the entire data set.\n",
      "* :class:`diogenes.grid_search.subset.SubsetRandomRowsEvenDistribution`, which takes a subset of data that have an equal number\n",
      "  of representatives with each label.\n",
      "* :class:`diogenes.grid_search.subset.SubsetSweepVaryStratification`, which varies the distribution of rows with each label.\n",
      "* :class:`diogenes.grid_search.subset.SubsetNoSubset`, which simply returns all the data rather than taking a subset. This is\n",
      "  what `Experiment` uses when you do not specify a subset iterator.\n",
      "  \n",
      "As an example, we will examine the performance of Random Forest when we provide different numbers of rows. We want to vary number of rows without varying the distribution of labels, so we will use `SubsetRandomRowsActualDistribution`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subsets = [{'subset': diogenes.grid_search.subset.SubsetRandomRowsActualDistribution,\n",
      "            'subset_size': range(1000, M.shape[0], 500),\n",
      "            'n_subsets': [1]}]\n",
      "exp = diogenes.grid_search.experiment.Experiment(M, labels, subsets=subsets)\n",
      "subset_size = []\n",
      "all_scores = []\n",
      "for trial, score in exp.average_score().iteritems():\n",
      "    subset_size.append(trial.subset_params['subset_size'])\n",
      "    all_scores.append(score)\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "plt.plot(subset_size, all_scores, '.', markersize=10)\n",
      "plt.xlabel('subset size')\n",
      "plt.ylabel('score')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEPCAYAAACOU4kjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3/8DU/Ybu9h28zAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10d6e04d0>"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see a weak upward trend, but it isn't clear that Random Forest is sensitive to the size of the dataset given a constant proportion of labels."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Partition Iterators\n",
      "\n",
      "A partition iterator is a class that iterates over train and test sets. Iterators in Scikit Learn's [cross-validation module](http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators) are valid partition iterators, including:\n",
      "\n",
      "* [K-Fold cross-validation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.KFold.html#sklearn.cross_validation.KFold)\n",
      "* [Stratified K-Fold cross-validation](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedKFold.html#sklearn.cross_validation.StratifiedKFold)\n",
      "\n",
      "Here's an experiment that does 5 folds of stratified K-Fold cross validation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import StratifiedKFold\n",
      "cvs = [{'cv': StratifiedKFold, 'n_folds': [5]}]\n",
      "exp = diogenes.grid_search.experiment.Experiment(M, labels, cvs=cvs)\n",
      "exp.run()\n",
      "print exp.trials\n",
      "for run in exp.trials[0].runs_flattened():\n",
      "    print run.score()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[Trial(clf=<class 'sklearn.ensemble.forest.RandomForestClassifier'>, clf_params={}, subset=<class 'diogenes.grid_search.subset.SubsetNoSubset'>, subset_params={}, cv=<class 'sklearn.cross_validation.StratifiedKFold'>, cv_params={'n_folds': 5})]\n",
        "0.698979591837\n",
        "0.702040816327\n",
        "0.755102040816\n",
        "0.723186925434\n",
        "0.746680286006\n"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have 1 `Trial` with 5 `Run`s, one `Run` per fold. We discuss `Trial`s and `Run`s in more detail below."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In addition to the Scikit Learn partition iterators, we define partition iterators in :mod:`diogenes.grid_search.partition_iterator`, including:\n",
      "\n",
      "#### SlidingWindowIdx\n",
      "\n",
      ":class:`diogenes.grid_search.partition_iterator.SlidingWindowIdx` takes a sliding window of rows for the test set and a   sliding window of rows for the training set. For example, if we create:\n",
      "\n",
      "    cvs = [{'cv': diogenes.grid_search.partition_iterator.SlidingWindowIdx,\n",
      "            'train_start': [10],\n",
      "            'train_window_size': [20],\n",
      "            'test_start': [30],\n",
      "            'test_window_size': [20],\n",
      "            'inc_value': [10]}]\n",
      "                                                             \n",
      "then the following rows will be included in our train and test sets:\n",
      "  \n",
      "| train set start row | train set stop row | test set start row | test set stop row |\n",
      "|---------------------|--------------------|--------------------|-------------------|\n",
      "| 10                  | 30                 | 30                 | 50                |\n",
      "| 20                  | 40                 | 40                 | 60                |\n",
      "| 30                  | 50                 | 50                 | 70                |\n",
      "| ...                 | ...                | ...                | ...               |\n",
      "\n",
      "We can also set `'expanding_train': True`, which keeps the train test start row constant\n",
      "\n",
      "| train set start row | train set stop row | test set start row | test set stop row |\n",
      "|---------------------|--------------------|--------------------|-------------------|\n",
      "| 10                  | 30                 | 30                 | 50                |\n",
      "| 10                  | 40                 | 40                 | 60                |\n",
      "| 10                  | 50                 | 50                 | 70                |\n",
      "| ...                 | ...                | ...                | ...               |\n",
      "\n",
      "#### SlidingWindowValue\n",
      "\n",
      ":class:`diogenes.grid_search.partition_iterator.SlidingWindowValue` is similar to `SlidingWindowIdx` except instead of using row numbers as an index, it uses the value of a given column. This is designed for cross-validating over time. For example, let's say each of our rows happened during a particular year:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(0)\n",
      "years = np.random.randint(1990, 2000, size=(M.shape[0],))\n",
      "print years[:10]\n",
      "M_with_year = diogenes.utils.append_cols(M, years, 'year')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[1995 1990 1993 1993 1997 1999 1993 1995 1992 1994]\n"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cvs = [{'cv': diogenes.grid_search.partition_iterator.SlidingWindowValue,\n",
      "        'guide_col_name': ['year'],\n",
      "        'train_start': [1990],\n",
      "        'train_window_size': [2],\n",
      "        'test_start': [1992],\n",
      "        'test_window_size': [2],\n",
      "        'inc_value': [2]}]\n",
      "\n",
      "exp = diogenes.grid_search.experiment.Experiment(M_with_year, labels, cvs=cvs)\n",
      "exp.run()\n",
      "\n",
      "for run in exp.trials[0].runs_flattened():\n",
      "    print 'train_start: {}, train_end: {}, test_start: {}, test_end: {}, score: {}'.format(\n",
      "        run.cv_note['train_start'],\n",
      "        run.cv_note['train_end'],\n",
      "        run.cv_note['test_start'],\n",
      "        run.cv_note['test_end'],\n",
      "        run.score())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train_start: 1990, train_end: 1991, test_start: 1992, test_end: 1993, score: 0.765190525232\n",
        "train_start: 1992, train_end: 1993, test_start: 1994, test_end: 1995, score: 0.784913353721\n",
        "train_start: 1994, train_end: 1995, test_start: 1996, test_end: 1997, score: 0.760288065844\n",
        "train_start: 1996, train_end: 1997, test_start: 1998, test_end: 1999, score: 0.746435845214\n"
       ]
      }
     ],
     "prompt_number": 58
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Trials and Runs\n",
      "\n",
      "In diogenes, there are three levels used to keep track of fitting data to classifiers.\n",
      "\n",
      "* :class:`diogenes.grid_search.experiment.Experiment` tests a number of classifiers, hyperparameters, subsets, and partition \n",
      "  iterators. `Experiments` contain a number of `Trials`.\n",
      "* :class:`diogenes.grid_search.experiment.Trial` contains one configuration-- i.e. one classifier, one set of hyperparameters,\n",
      "  one method of taking subsets, and one method of doing cross-validation. a `Trial` contains a number of `Runs`\n",
      "* :class:`diogenes.grid_search.experiment.Run` contains one fold of one subset of data. \n",
      "\n",
      "For example, we'll design an experiment with multiple hyperparameters, subsets, and folds:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clfs = [{'clf': RandomForestClassifier, 'n_estimators': [10, 50]}]\n",
      "subsets = [{'subset': diogenes.grid_search.subset.SubsetRandomRowsEvenDistribution, \n",
      "            'subset_size': [500, 1000],\n",
      "            'n_subsets': [3]}]\n",
      "cvs = [{'cv': StratifiedKFold, 'n_folds': [4]}]\n",
      "exp = diogenes.grid_search.experiment.Experiment(M, labels, clfs=clfs, subsets=subsets, cvs=cvs)\n",
      "_ = exp.run()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can access our `Trial`s with `exp.trials`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for trial in exp.trials:\n",
      "    print 'trial with n_estimators={} and subset_size={}'.format(\n",
      "        trial.clf_params['n_estimators'],\n",
      "        trial.subset_params['subset_size'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "trial with n_estimators=10 and subset_size=500\n",
        "trial with n_estimators=10 and subset_size=1000\n",
        "trial with n_estimators=50 and subset_size=500\n",
        "trial with n_estimators=50 and subset_size=1000\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We have 4 `Trial`s: one `Trial` for each configuration. In this case, our configuration varies by `n_estimators` for Random Forest and `subset_size` for our `SubsetRandomRowsEvenDistribution` subset iterator.\n",
      "\n",
      "`Trial`s expose things like \n",
      "* The classifier, subset iterator, and partition iterator classes associated with the `Trial` \n",
      "  (`Trial.clf`, `Trial.subset`, `Trial.cv`).\n",
      "* The set of parameters associated with the classifier, subset iterator, and partition iterator \n",
      "  (`Trial.clf_params`, `Trial.subset_params`, `Trial.cv_params`)\n",
      "\n",
      "We can access the `Run`s in a given `Trial` with `Trial.runs`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trial_0 = exp.trials[0]\n",
      "for runs_by_subset in trial_0.runs:\n",
      "    for run in runs_by_subset:\n",
      "        print 'Run from subset: {}, fold: {}'.format(\n",
      "            run.subset_note['sample_num'],\n",
      "            run.cv_note['fold'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Run from subset: 0, fold: 0\n",
        "Run from subset: 0, fold: 1\n",
        "Run from subset: 0, fold: 2\n",
        "Run from subset: 0, fold: 3\n",
        "Run from subset: 1, fold: 0\n",
        "Run from subset: 1, fold: 1\n",
        "Run from subset: 1, fold: 2\n",
        "Run from subset: 1, fold: 3\n",
        "Run from subset: 2, fold: 0\n",
        "Run from subset: 2, fold: 1\n",
        "Run from subset: 2, fold: 2\n",
        "Run from subset: 2, fold: 3\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that `Trial.runs` is a list of lists. The outer list organizes subsets and the inner list organizes folds. To get a flat list, use `Trial.runs_flattened()`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for run in trial_0.runs_flattened():\n",
      "    print 'Run from subset: {}, fold: {}'.format(\n",
      "            run.subset_note['sample_num'],\n",
      "            run.cv_note['fold'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Run from subset: 0, fold: 0\n",
        "Run from subset: 0, fold: 1\n",
        "Run from subset: 0, fold: 2\n",
        "Run from subset: 0, fold: 3\n",
        "Run from subset: 1, fold: 0\n",
        "Run from subset: 1, fold: 1\n",
        "Run from subset: 1, fold: 2\n",
        "Run from subset: 1, fold: 3\n",
        "Run from subset: 2, fold: 0\n",
        "Run from subset: 2, fold: 1\n",
        "Run from subset: 2, fold: 2\n",
        "Run from subset: 2, fold: 3\n"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In general, metrics and graphs are available at the `Run` level and aggregations of metrics are available at the `Trial` level"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print trial_0.average_score()\n",
      "\n",
      "run_0 = trial_0.runs_flattened()[0]\n",
      "print run_0.f1_score()\n",
      "fig = run_0.prec_recall_curve()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.674880525687\n",
        "0.691729323308\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAEZCAYAAADc7YGjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIiIiIiIiIiIiIiIiIiIiIiKSvf4fm06WIydhwJAAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x10c59d350>"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`Run`s also expose things like:\n",
      "\n",
      "* the fitted clf (`Run.clf`) \n",
      "* the train and test indices of `M` and `labels` applicable to the run (`Run.train_indices`, `Run.test_indices`)\n",
      "* Information about the subset `Run.subset_note` and fold `Run.cv_note` to which the run belongs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Reports\n",
      "\n",
      "`Experiments` offer two primary kinds of reports: \n",
      "* A pdf report, which summarizes the performance of various `Trials` and provides detailed metrics for the best `Trial`\n",
      "  (:meth:`diogenes.grid_search.experiment.Experiment.make_report`)\n",
      "* A csv report, which elucidates the performance of all runs in a format that can be processed later (e.g. by MS Excel).\n",
      "  (:meth:`diogenes.grid_search.experiment.Experiment.make_csv`)\n",
      "\n",
      "We'll look at the pdf report in detail:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clfs = [{'clf': RandomForestClassifier, 'n_estimators': [10,50],\n",
      "         'max_features': ['sqrt','log2'], 'random_state': [0]}]\n",
      "exp = diogenes.grid_search.experiment.Experiment(M, labels, clfs=clfs)\n",
      "exp.run()\n",
      "exp.make_report(report_file_name='grid_search_sample_report.pdf', verbose=False)\n",
      "from IPython.display import HTML\n",
      "HTML('<iframe src=grid_search_sample_report.pdf width=800 height=350></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src=grid_search_sample_report.pdf width=800 height=350></iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "<IPython.core.display.HTML at 0x10c59d050>"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first two graphs are summaries of how well the `Trial`s performed by two different metrics (classifier.score and area under ROC, respectively). The number above the bar signifies the configuration, which can be looked up in the legend at the end of the report. Here, we see that the best `Trial` by both metrics is trial 2, which, as we can see in the legend, has 50 estimators and `'sqrt'` for its `max_features`. The second two graphs are ROC and precision/recall for trial 2."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    }
   ],
   "metadata": {}
  }
 ]
}